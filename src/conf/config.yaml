# Production Environment Configuration

server:
  host: '0.0.0.0'
  port: 5000
  debug: false
  workers: 4

logging:
  level: 'INFO'
  file_rotation: true
  max_bytes: 52428800  # 50MB
  backup_count: 20

# 向量化配置
embedding:
  model_name: 'all-MiniLM-L6-v2'  # sentence-transformers模型
  cache_dir: '.cache/sentence_transformers'  # 模型缓存目录
  batch_size: 32  # 批处理大小
  max_length: 512  # 最大文本长度

# MySQL数据库配置
database:
  mysql:
    host: 'localhost'
    port: 3306
    user: 'root'
    password: 'password'
    database: 'financial_db'
    charset: 'utf8mb4'
    pool_size: 10
    max_overflow: 20
    pool_timeout: 30
    pool_recycle: 3600
    echo: false

# Milvus向量数据库配置
milvus:
  host: 'localhost'  # Milvus服务器地址
  port: '19530'      # Milvus端口
  collection_name: 'financial_sql_context'  # 集合名称
  index_params:
    metric_type: 'COSINE'  # 距离度量方式
    index_type: 'IVF_FLAT'  # 索引类型
    nlist: 128  # 聚类数量

api:
  openai:
    timeout: 90
    retry:
      max_attempts: 5
      initial_delay: 2
    rate_limit:
      requests_per_minute: 200
  
  qwen:
    api_key: "${QWEN_API_KEY}"  # 请设置环境变量 QWEN_API_KEY
    endpoint: "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
    timeout: 30
    model_version: "qwen-turbo"
    segment_model: "qwen-turbo"
    ner_model: "qwen-turbo"
    intent_model: "qwen-turbo"
    model_list:
      - qwen-turbo  # 快速模型
      - qwen-plus   # 高级模型
      - qwq-plus    # 流式高级模型
    # 是否全局启用流式输出(可在运行时动态更改) 
    stream_enabled: true
    # 流式输出的模型列表(这些模型会使用流式API)
    streaming_models:
      - qwq-32b
      - qwq-plus
      - qwq-plus-latest
    retry:
      max_attempts: 3
      initial_delay: 1
    rate_limit:
      requests_per_minute: 60
    default_params:
      temperature: 0.01  # 极低温度，确保输出一致性
      top_p: 0.99
      max_tokens: 3000  # 减少最大token数
      top_k: 20  # 进一步限制词汇选择范围
      repetition_penalty: 1.3  # 增加重复惩罚 