import sys
from pathlib import Path
import logging
from typing import TypedDict, List, Dict, Optional, Any, Annotated, Literal
from dataclasses import dataclass, field
from datetime import datetime
import json
import hashlib
from abc import ABC, abstractmethod
from pydantic import BaseModel
from langchain_core.prompts import PromptTemplate
from langchain_core.tools import Tool
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langchain_core.callbacks import BaseCallbackHandler
import re

# Add project root to path first
project_root = Path(__file__).resolve().parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

# Now import local modules
from src.models.streaming_adapter import StreamingLLMAdapter
from src.utils.logger import get_logger
from src.config.config_manager import ConfigManager
from src.tools.db_tool import query_db, check_db_info
from src.tools.embedding_tool import embedding_search
from src.tools.es_tool import search_es
from src.tools.file_tool import select_file
from src.tools.query2sql import query_to_sql
from src.prompts import REACT_PROMPT


log = get_logger()

tools = [
    Tool(
        name="ESSearch",
        description="Search the ES index",
        func=search_es
    ),
    Tool(
        name="QueryDB",
        description="Query the DB",
        func=query_db
    ),
    Tool(
        name="EmbeddingSearch",
        description="Search the embedding index",
        func=embedding_search
    ),
    Tool(
        name="QueryToSQL",
        description="Query the DB to SQL",
        func=query_to_sql
    ),
    Tool(
        name="SelectFile",
        description="Select the file",
        func=select_file
    ),
    Tool(
        name="CheckDBInfo",
        description="Check the DB info",
        func=check_db_info
    ),
]

# å®šä¹‰çŠ¶æ€ç±»å‹
class AgentState(TypedDict):
    """Agentæ‰§è¡ŒçŠ¶æ€"""
    messages: List[Dict[str, Any]]  # æ¶ˆæ¯å†å²
    current_step: int  # å½“å‰æ­¥éª¤
    max_steps: int  # æœ€å¤§æ­¥éª¤æ•°
    scratchpad: str  # æ¨ç†è¿‡ç¨‹è®°å½•
    tool_results: List[Dict[str, Any]]  # å·¥å…·æ‰§è¡Œç»“æœ
    final_answer: Optional[str]  # æœ€ç»ˆç­”æ¡ˆ
    error: Optional[str]  # é”™è¯¯ä¿¡æ¯
    is_finished: bool  # æ˜¯å¦å®Œæˆ


class ResponseFormat(BaseModel):
    """Response format for the agent."""
    result: str


class ToolExecutionCallback(BaseCallbackHandler):
    """å·¥å…·æ‰§è¡Œå›è°ƒå¤„ç†å™¨ï¼Œç”¨äºç›‘æ§å·¥å…·è°ƒç”¨"""
    
    def __init__(self):
        self.log = get_logger()
        self.tool_calls = []
        self.current_tool = None
    
    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs):
        """å·¥å…·å¼€å§‹æ‰§è¡Œæ—¶çš„å›è°ƒ"""
        tool_name = serialized.get("name", "unknown")
        self.log.info(f"[TOOL_START] {tool_name} å¼€å§‹æ‰§è¡Œ")
        self.log.info(f"[TOOL_INPUT] {tool_name} è¾“å…¥: {input_str}")
        
        self.current_tool = {
            "name": tool_name,
            "input": input_str,
            "start_time": datetime.now()
        }
    
    def on_tool_end(self, output: str, **kwargs):
        """å·¥å…·æ‰§è¡Œç»“æŸæ—¶çš„å›è°ƒ"""
        if self.current_tool:
            tool_name = self.current_tool["name"]
            end_time = datetime.now()
            duration = (end_time - self.current_tool["start_time"]).total_seconds()
            
            self.log.info(f"[TOOL_END] {tool_name} æ‰§è¡Œå®Œæˆ (è€—æ—¶: {duration:.2f}s)")
            self.log.info(f"[TOOL_OUTPUT] {tool_name} è¾“å‡º: {output}")
            
            self.tool_calls.append({
                **self.current_tool,
                "output": output,
                "end_time": end_time,
                "duration": duration
            })
            self.current_tool = None
    
    def on_tool_error(self, error: str, **kwargs):
        """å·¥å…·æ‰§è¡Œé”™è¯¯æ—¶çš„å›è°ƒ"""
        if self.current_tool:
            tool_name = self.current_tool["name"]
            self.log.error(f"[TOOL_ERROR] {tool_name} æ‰§è¡Œå¤±è´¥: {error}")
            
            self.tool_calls.append({
                **self.current_tool,
                "error": error,
                "end_time": datetime.now()
            })
            self.current_tool = None
    
    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs):
        """LLMå¼€å§‹æ‰§è¡Œæ—¶çš„å›è°ƒ"""
        self.log.info(f"[LLM_START] æ¨¡å‹å¼€å§‹æ¨ç†")
    
    def on_llm_end(self, response, **kwargs):
        """LLMæ‰§è¡Œç»“æŸæ—¶çš„å›è°ƒ"""
        self.log.info(f"[LLM_END] æ¨¡å‹æ¨ç†å®Œæˆ")
    
    def on_llm_error(self, error: str, **kwargs):
        """LLMæ‰§è¡Œé”™è¯¯æ—¶çš„å›è°ƒ"""
        self.log.error(f"[LLM_ERROR] æ¨¡å‹æ¨ç†å¤±è´¥: {error}")
    
    def get_tool_execution_summary(self):
        """è·å–å·¥å…·æ‰§è¡Œæ‘˜è¦"""
        return {
            "total_tools": len(self.tool_calls),
            "tools": self.tool_calls
        }


class CustomReActAgent:
    """
    è‡ªå®šä¹‰ReAct Agentå®ç°
    
    åŸºäºLangGraphæ„å»ºï¼Œæ”¯æŒï¼š
    - å®Œå…¨å¯æ§çš„æ¨ç†æµç¨‹
    - å·¥å…·è°ƒç”¨
    - æµå¼è¾“å‡º
    - çŠ¶æ€ç®¡ç†
    - é”™è¯¯å¤„ç†
    - è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—
    - å¯å®šåˆ¶çš„æ¨ç†æ­¥éª¤
    """
    
    def __init__(
        self,
        model_name: str = "qwen-turbo",
        tools: Optional[List[Tool]] = None,
        prompt: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None,
        max_steps: int = 10,
        **kwargs
    ):
        """
        åˆå§‹åŒ–è‡ªå®šä¹‰ReAct Agent
        
        Args:
            model_name: æ¨¡å‹åç§°
            tools: å·¥å…·åˆ—è¡¨
            prompt: è‡ªå®šä¹‰prompt
            config: é…ç½®ç®¡ç†å™¨
            max_steps: æœ€å¤§æ¨ç†æ­¥éª¤æ•°
            **kwargs: å…¶ä»–å‚æ•°
        """
        self.model_name = model_name
        self.tools = tools or []
        self.prompt = prompt or REACT_PROMPT
        self.config = config
        self.max_steps = max_steps
        self.log = get_logger()
        
        # åˆå§‹åŒ–å›è°ƒå¤„ç†å™¨
        self.callback_handler = ToolExecutionCallback()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.llm = StreamingLLMAdapter(
            model=model_name,
            api_key=self.config.get("api.qwen.api_key"),
            base_url=self.config.get("api.qwen.base_url"),
            streaming_models=self.config.get("api.qwen.streaming_models"),
            stream_enabled=self.config.get("api.qwen.stream_enabled"),
            default_params=self.config.get("api.qwen.default_params"),
            **kwargs
        )
        
        # åˆ›å»ºå·¥å…·æ˜ å°„
        self.tool_map = {tool.name: tool for tool in self.tools}
        
        # åˆ›å»ºè‡ªå®šä¹‰ReActå›¾
        self.app = self._create_custom_react_graph()
        
        self.log.info(f"Custom ReAct Agent initialized with model: {model_name}, max_steps: {max_steps}")
    
    def _create_custom_react_graph(self):
        """
        åˆ›å»ºè‡ªå®šä¹‰ReActæ‰§è¡Œå›¾
        
        Returns:
            LangGraph StateGraphå®ä¾‹
        """
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("tools", self._tools_node)
        
        # è®¾ç½®å…¥å£å’Œå‡ºå£
        workflow.set_entry_point("agent")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {
                "tools": "tools",
                "end": END
            }
        )
        
        workflow.add_edge("tools", "agent")
        
        # ç¼–è¯‘å›¾
        return workflow.compile()
    
    def _agent_node(self, state: AgentState) -> AgentState:
        """
        Agentæ¨ç†èŠ‚ç‚¹
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        try:
            # å¢åŠ æ­¥éª¤è®¡æ•°
            state["current_step"] += 1
            self.log.info(f"[AGENT_NODE] æ­¥éª¤ {state['current_step']} - å¼€å§‹æ¨ç†")
            
            # æ„å»ºå®Œæ•´çš„prompt
            full_prompt = self._build_prompt(state)
            
            # è°ƒç”¨LLM
            response = self.llm.invoke(full_prompt)
            
            # è§£æå“åº”
            parsed_response = self._parse_agent_response(response)
            
            # æ›´æ–°çŠ¶æ€
            state["scratchpad"] += f"\n{parsed_response['thought']}\n{parsed_response['action']}"
            
            if parsed_response["action_type"] == "finish":
                state["final_answer"] = parsed_response["action_input"]
                state["is_finished"] = True
                self.log.info(f"[AGENT_NODE] æ¨ç†å®Œæˆï¼Œæœ€ç»ˆç­”æ¡ˆ: {state['final_answer']}")
            else:
                # å‡†å¤‡å·¥å…·è°ƒç”¨
                state["next_tool"] = {
                    "name": parsed_response["action_input"],
                    "input": parsed_response.get("tool_input", "")
                }
                self.log.info(f"[AGENT_NODE] å‡†å¤‡è°ƒç”¨å·¥å…·: {parsed_response['action_input']}")
            
            return state
            
        except Exception as e:
            self.log.error(f"[AGENT_NODE] æ¨ç†å¤±è´¥: {e}")
            state["error"] = str(e)
            state["is_finished"] = True
            return state
    
    def _tools_node(self, state: AgentState) -> AgentState:
        """
        å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        try:
            tool_info = state.get("next_tool")
            if not tool_info:
                state["error"] = "No tool to execute"
                state["is_finished"] = True
                return state
            
            tool_name = tool_info["name"]
            tool_input = tool_info["input"]
            
            self.log.info(f"[TOOLS_NODE] æ‰§è¡Œå·¥å…·: {tool_name}")
            
            # æŸ¥æ‰¾å·¥å…·
            if tool_name not in self.tool_map:
                error_msg = f"Tool '{tool_name}' not found"
                self.log.error(f"[TOOLS_NODE] {error_msg}")
                state["error"] = error_msg
                state["is_finished"] = True
                return state
            
            tool = self.tool_map[tool_name]
            
            # æ‰§è¡Œå·¥å…·
            try:
                tool_result = tool.func(tool_input)
                self.log.info(f"[TOOLS_NODE] å·¥å…·æ‰§è¡ŒæˆåŠŸ: {tool_result}")
                
                # æ·»åŠ å·¥å…·ç»“æœåˆ°çŠ¶æ€
                state["tool_results"].append({
                    "tool": tool_name,
                    "input": tool_input,
                    "output": tool_result,
                    "step": state["current_step"]
                })
                
                # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°scratchpad
                state["scratchpad"] += f"\nObservation: {tool_result}"
                
            except Exception as e:
                error_msg = f"Tool execution failed: {str(e)}"
                self.log.error(f"[TOOLS_NODE] {error_msg}")
                state["error"] = error_msg
                state["is_finished"] = True
                return state
            
            # æ¸…ç†next_tool
            if "next_tool" in state:
                del state["next_tool"]
            
            return state
            
        except Exception as e:
            self.log.error(f"[TOOLS_NODE] å·¥å…·èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {e}")
            state["error"] = str(e)
            state["is_finished"] = True
            return state
    
    def _should_continue(self, state: AgentState) -> str:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»§ç»­æ‰§è¡Œ
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
        """
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if state.get("is_finished", False):
            return "end"
        
        # æ£€æŸ¥æ­¥éª¤æ•°é™åˆ¶
        if state["current_step"] >= state["max_steps"]:
            state["error"] = f"Maximum steps ({state['max_steps']}) reached"
            state["is_finished"] = True
            return "end"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·éœ€è¦æ‰§è¡Œ
        if "next_tool" in state:
            return "tools"
        
        # ç»§ç»­æ¨ç†
        return "end"
    
    def _build_prompt(self, state: AgentState) -> str:
        """
        æ„å»ºå®Œæ•´çš„prompt
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            å®Œæ•´çš„promptå­—ç¬¦ä¸²
        """
        # è·å–å·¥å…·æè¿°
        tools_description = "\n".join([
            f"- {tool.name}: {tool.description}" 
            for tool in self.tools
        ])
        
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = ""
        if state["messages"]:
            user_input = state["messages"][-1].get("content", "")
        
        # æ„å»ºprompt
        prompt = self.prompt.format(
            tools=tools_description,
            input=user_input,
            agent_scratchpad=state["scratchpad"]
        )
        
        return prompt
    
    def _parse_agent_response(self, response: str) -> Dict[str, Any]:
        """
        è§£æAgentå“åº”
        
        Args:
            response: LLMå“åº”
            
        Returns:
            è§£æåçš„å“åº”å­—å…¸
        """
        try:
            # æå–Thought
            thought_match = re.search(r'Thought\s*\d*:\s*(.*?)(?=\nAction|\n$)', response, re.DOTALL)
            thought = thought_match.group(1).strip() if thought_match else ""
            
            # æå–Action
            action_match = re.search(r'Action\s*\d*:\s*(.*?)(?=\n|$)', response, re.DOTALL)
            action = action_match.group(1).strip() if action_match else ""
            
            # è§£æAction
            if action.lower().startswith("finish"):
                # æå–æœ€ç»ˆç­”æ¡ˆ
                answer_match = re.search(r'finish\[(.*?)\]', action, re.IGNORECASE)
                answer = answer_match.group(1) if answer_match else action
                
                return {
                    "thought": thought,
                    "action": action,
                    "action_type": "finish",
                    "action_input": answer
                }
            else:
                # å·¥å…·è°ƒç”¨
                tool_name = action.strip()
                return {
                    "thought": thought,
                    "action": action,
                    "action_type": "tool",
                    "action_input": tool_name
                }
                
        except Exception as e:
            self.log.error(f"Failed to parse agent response: {e}")
            return {
                "thought": "",
                "action": "",
                "action_type": "error",
                "action_input": str(e)
            }
    
    def invoke(self, input_text: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œagentæ¨ç†
        
        Args:
            input_text: è¾“å…¥æ–‡æœ¬
        Returns:
            agentæ‰§è¡Œç»“æœ
        """
        try:
            self.log.info(f"[AGENT_START] å¼€å§‹æ‰§è¡ŒAgentæ¨ç†")
            self.log.info(f"[AGENT_INPUT] è¾“å…¥: {input_text}")
            
            # åˆå§‹åŒ–çŠ¶æ€
            initial_state = {
                "messages": [{"role": "user", "content": input_text}],
                "current_step": 0,
                "max_steps": self.max_steps,
                "scratchpad": "",
                "tool_results": [],
                "final_answer": None,
                "error": None,
                "is_finished": False
            }
            
            # å‡†å¤‡å›è°ƒ
            callbacks = [self.callback_handler]
            
            # æ‰§è¡Œå›¾
            result = self.app.invoke(initial_state, config={"callbacks": callbacks})
            
            self.log.info(f"[AGENT_END] Agentæ¨ç†å®Œæˆ")
            
            # æ„å»ºè¿”å›ç»“æœ
            response = {
                "final_answer": result.get("final_answer"),
                "error": result.get("error"),
                "scratchpad": result.get("scratchpad"),
                "tool_results": result.get("tool_results", []),
                "steps_taken": result.get("current_step", 0)
            }
            
            # æ·»åŠ å·¥å…·æ‰§è¡Œæ‘˜è¦
            if self.callback_handler:
                tool_summary = self.callback_handler.get_tool_execution_summary()
                response["tool_execution_summary"] = tool_summary
                self.log.info(f"[TOOL_SUMMARY] å·¥å…·æ‰§è¡Œæ‘˜è¦: {tool_summary}")
            
            return response
            
        except Exception as e:
            self.log.error(f"[AGENT_ERROR] Agentæ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    def stream(self, input_text: str):
        """
        æµå¼æ‰§è¡Œagentæ¨ç†
        
        Args:
            input_text: è¾“å…¥æ–‡æœ¬
            
        Yields:
            æµå¼è¾“å‡ºç»“æœ
        """
        try:
            self.log.info(f"[AGENT_STREAM_START] å¼€å§‹æµå¼æ‰§è¡ŒAgentæ¨ç†")
            self.log.info(f"[AGENT_INPUT] è¾“å…¥: {input_text}")
            
            # åˆå§‹åŒ–çŠ¶æ€
            initial_state = {
                "messages": [{"role": "user", "content": input_text}],
                "current_step": 0,
                "max_steps": self.max_steps,
                "scratchpad": "",
                "tool_results": [],
                "final_answer": None,
                "error": None,
                "is_finished": False
            }
            
            # å‡†å¤‡å›è°ƒ
            callbacks = [self.callback_handler]
            
            # æµå¼æ‰§è¡Œå›¾
            for chunk in self.app.stream(initial_state, config={"callbacks": callbacks}):
                yield chunk
                
            self.log.info(f"[AGENT_STREAM_END] æµå¼æ‰§è¡Œå®Œæˆ")
                
        except Exception as e:
            self.log.error(f"[AGENT_STREAM_ERROR] æµå¼æ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    def add_tool(self, tool: Tool):
        """
        æ·»åŠ å·¥å…·åˆ°agent
        
        Args:
            tool: è¦æ·»åŠ çš„å·¥å…·
        """
        self.tools.append(tool)
        self.tool_map[tool.name] = tool
        self.log.info(f"Added tool: {tool.name}")
    
    def remove_tool(self, tool_name: str):
        """
        ä»agentä¸­ç§»é™¤å·¥å…·
        
        Args:
            tool_name: è¦ç§»é™¤çš„å·¥å…·åç§°
        """
        self.tools = [tool for tool in self.tools if tool.name != tool_name]
        if tool_name in self.tool_map:
            del self.tool_map[tool_name]
        self.log.info(f"Removed tool: {tool_name}")
    
    def get_tools(self) -> List[Tool]:
        """
        è·å–å½“å‰æ‰€æœ‰å·¥å…·
        
        Returns:
            å·¥å…·åˆ—è¡¨
        """
        return self.tools.copy()
    
    def update_prompt(self, new_prompt: str):
        """
        æ›´æ–°agentçš„prompt
        
        Args:
            new_prompt: æ–°çš„promptæ¨¡æ¿
        """
        self.prompt = new_prompt
        self.log.info("Updated agent prompt")
    
    def set_max_steps(self, max_steps: int):
        """
        è®¾ç½®æœ€å¤§æ¨ç†æ­¥éª¤æ•°
        
        Args:
            max_steps: æœ€å¤§æ­¥éª¤æ•°
        """
        self.max_steps = max_steps
        self.log.info(f"Updated max steps to: {max_steps}")
    
    def get_execution_summary(self) -> Dict[str, Any]:
        """
        è·å–æ‰§è¡Œæ‘˜è¦
        
        Returns:
            æ‰§è¡Œæ‘˜è¦ä¿¡æ¯
        """
        if self.callback_handler:
            return self.callback_handler.get_tool_execution_summary()
        return {"total_tools": 0, "tools": []}


# åˆ›å»ºé»˜è®¤çš„è‡ªå®šä¹‰ReAct Agentå®ä¾‹
def create_default_custom_react_agent(
    model_name: str = "qwen-turbo",
    custom_tools: Optional[List[Tool]] = None,
    custom_prompt: Optional[str] = None,
    max_steps: int = 10,
    **kwargs
) -> CustomReActAgent:
    """
    åˆ›å»ºé»˜è®¤çš„è‡ªå®šä¹‰ReAct Agentå®ä¾‹
    
    Args:
        model_name: æ¨¡å‹åç§°
        custom_tools: è‡ªå®šä¹‰å·¥å…·åˆ—è¡¨
        custom_prompt: è‡ªå®šä¹‰prompt
        max_steps: æœ€å¤§æ¨ç†æ­¥éª¤æ•°
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        CustomReActAgentå®ä¾‹
    """
    # ä½¿ç”¨é»˜è®¤å·¥å…·æˆ–è‡ªå®šä¹‰å·¥å…·
    agent_tools = custom_tools if custom_tools is not None else tools
    
    return CustomReActAgent(
        model_name=model_name,
        tools=agent_tools,
        prompt=custom_prompt,
        max_steps=max_steps,
        **kwargs
    )


def main():
    """ä¸»ç¤ºä¾‹å‡½æ•°"""
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    from src.utils.logger import logger as async_logger
    async_logger.init()  # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    
    # è·å–æ—¥å¿—å™¨
    logger = get_logger()
    config = ConfigManager()
    
    # åˆå§‹åŒ–é…ç½®
    config_dir = Path(__file__).resolve().parent.parent / "conf"
    config.init(config_dir)
    
    # åˆ›å»ºè‡ªå®šä¹‰ReAct Agent
    logger.info("åˆå§‹åŒ–è‡ªå®šä¹‰ReAct Agent...")
    agent = create_default_custom_react_agent(
        model_name="qwen-turbo",
        config=config,
        max_steps=8
    )
    
    # ç¤ºä¾‹æŸ¥è¯¢åˆ—è¡¨
    query = "è¯·å¸®æˆ‘æŸ¥è¯¢å‡º20210415æ—¥ï¼Œå»ºç­‘ææ–™ä¸€çº§è¡Œä¸šæ¶¨å¹…è¶…è¿‡5%ï¼ˆä¸åŒ…å«ï¼‰çš„è‚¡ç¥¨æ•°é‡ã€‚"
    
    logger.info("å¼€å§‹æ‰§è¡ŒæŸ¥è¯¢...")
    print("=" * 50)
    print("æŸ¥è¯¢ç»“æœ:")
    print("=" * 50)
    
    try:
        # ä½¿ç”¨æ–°ç‰ˆæœ¬çš„invokeæ–¹æ³•
        result = agent.invoke(query)
        
        print(f"æœ€ç»ˆç­”æ¡ˆ: {result.get('final_answer')}")
        print(f"æ¨ç†æ­¥éª¤: {result.get('steps_taken')}")
        print(f"å·¥å…·è°ƒç”¨æ¬¡æ•°: {len(result.get('tool_results', []))}")
        
        if result.get('error'):
            print(f"é”™è¯¯ä¿¡æ¯: {result['error']}")
        
        logger.info(f"æŸ¥è¯¢ç»“æœ: {result}")
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}")
    
    print("=" * 50)
    logger.info("æŸ¥è¯¢å®Œæˆ")


def demo_streaming():
    """æ¼”ç¤ºæµå¼è¾“å‡ºåŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ”„ æµå¼è¾“å‡ºæ¼”ç¤º")
    print("="*60)
    
    # åˆ›å»ºagent
    agent = create_default_custom_react_agent()
    
    # æµå¼æŸ¥è¯¢
    query = "è¯·å¸®æˆ‘æ£€æŸ¥æ•°æ®åº“ä¿¡æ¯"
    
    try:
        print(f"ğŸ” æµå¼æŸ¥è¯¢: {query}")
        print("-" * 40)
        
        for chunk in agent.stream(query):
            print(f"ğŸ“¦ æ•°æ®å—: {chunk}")
            
    except Exception as e:
        print(f"âŒ æµå¼æŸ¥è¯¢å¤±è´¥: {e}")


if __name__ == "__main__":
    # è¿è¡ŒåŸºæœ¬ç¤ºä¾‹
    main()    
    # è¿è¡Œå…¶ä»–æ¼”ç¤º
    # demo_streaming()
