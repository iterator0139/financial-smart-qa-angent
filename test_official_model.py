#!/usr/bin/env python3
"""
ä½¿ç”¨å®˜æ–¹LangChainæ¨¡å‹æµ‹è¯•å·¥å…·è°ƒç”¨
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parent
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

from langchain_core.tools import Tool
from langgraph.prebuilt import create_react_agent
from src.config.config_manager import ConfigManager


def create_test_tool():
    """åˆ›å»ºä¸€ä¸ªæµ‹è¯•å·¥å…·"""
    
    def test_function(input_text: str) -> str:
        print(f"ğŸ¯ [REAL_TOOL_EXECUTION] å·¥å…·çœŸæ­£è¢«æ‰§è¡Œäº†ï¼")
        print(f"ğŸ“ [TOOL_INPUT] è¾“å…¥: {input_text}")
        result = f"å·¥å…·æ‰§è¡Œç»“æœ: {input_text}"
        print(f"ğŸ“¤ [TOOL_OUTPUT] è¾“å‡º: {result}")
        return result
    
    return Tool(
        name="TestTool",
        description="A test tool that prints execution logs",
        func=test_function
    )


def test_direct_tool_calling():
    """ç›´æ¥æµ‹è¯•å·¥å…·è°ƒç”¨"""
    print("\n=== ç›´æ¥æµ‹è¯•å·¥å…·è°ƒç”¨ ===")
    
    # åˆå§‹åŒ–é…ç½®
    config = ConfigManager()
    config_dir = Path(__file__).resolve().parent / "src" / "conf"
    config.init(config_dir)
    
    # è·å–OpenAIé…ç½®
    openai_api_key = config.get_config().get("api.openai.api_key")
    if not openai_api_key:
        print("âŒ æœªæ‰¾åˆ°OpenAI APIå¯†é’¥ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    # åˆ›å»ºæµ‹è¯•å·¥å…·
    test_tool = create_test_tool()
    
    try:
        # å°è¯•å¯¼å…¥OpenAI
        from langchain_openai import ChatOpenAI
        
        # åˆ›å»ºOpenAIæ¨¡å‹
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            api_key=openai_api_key,
            temperature=0
        )
        
        # ç»‘å®šå·¥å…·
        llm_with_tools = llm.bind_tools([test_tool])
        
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå·¥å…·å·²ç»‘å®š")
        
        # ç›´æ¥è°ƒç”¨æ¨¡å‹
        from langchain_core.messages import HumanMessage
        
        response = llm_with_tools.invoke([
            HumanMessage(content="è¯·ä½¿ç”¨TestToolå·¥å…·å¤„ç†ä¸€äº›æ•°æ®")
        ])
        
        print(f"ç›´æ¥è°ƒç”¨ç»“æœ: {response}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if hasattr(response, 'tool_calls') and response.tool_calls:
            print("ğŸ¯ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼")
            for tool_call in response.tool_calls:
                print(f"å·¥å…·åç§°: {tool_call['name']}")
                print(f"å·¥å…·å‚æ•°: {tool_call['args']}")
        else:
            print("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")
            
    except ImportError:
        print("âŒ æœªå®‰è£…langchain_openaiï¼Œå°è¯•ä½¿ç”¨å…¶ä»–æ¨¡å‹")
        try:
            from langchain_anthropic import ChatAnthropic
            
            # è·å–Anthropicé…ç½®
            anthropic_api_key = config.get_config().get("api.anthropic.api_key")
            if not anthropic_api_key:
                print("âŒ æœªæ‰¾åˆ°Anthropic APIå¯†é’¥ï¼Œè·³è¿‡æµ‹è¯•")
                return
            
            # åˆ›å»ºAnthropicæ¨¡å‹
            llm = ChatAnthropic(
                model="claude-3-haiku-20240307",
                api_key=anthropic_api_key,
                temperature=0
            )
            
            # ç»‘å®šå·¥å…·
            llm_with_tools = llm.bind_tools([test_tool])
            
            print("âœ… Anthropicæ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå·¥å…·å·²ç»‘å®š")
            
            # ç›´æ¥è°ƒç”¨æ¨¡å‹
            from langchain_core.messages import HumanMessage
            
            response = llm_with_tools.invoke([
                HumanMessage(content="è¯·ä½¿ç”¨TestToolå·¥å…·å¤„ç†ä¸€äº›æ•°æ®")
            ])
            
            print(f"ç›´æ¥è°ƒç”¨ç»“æœ: {response}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if hasattr(response, 'tool_calls') and response.tool_calls:
                print("ğŸ¯ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼")
                for tool_call in response.tool_calls:
                    print(f"å·¥å…·åç§°: {tool_call['name']}")
                    print(f"å·¥å…·å‚æ•°: {tool_call['args']}")
            else:
                print("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")
                
        except ImportError:
            print("âŒ æœªå®‰è£…ç›¸å…³ä¾èµ–åŒ…")
            print("è¯·å®‰è£…: pip install langchain-openai langchain-anthropic")
            
    except Exception as e:
        print(f"âŒ ç›´æ¥è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_with_agent():
    """ä½¿ç”¨Agentæµ‹è¯•"""
    print("\n=== ä½¿ç”¨Agentæµ‹è¯• ===")
    
    # åˆå§‹åŒ–é…ç½®
    config = ConfigManager()
    config_dir = Path(__file__).resolve().parent / "src" / "conf"
    config.init(config_dir)
    
    # åˆ›å»ºæµ‹è¯•å·¥å…·
    test_tool = create_test_tool()
    
    try:
        # å°è¯•å¯¼å…¥OpenAI
        from langchain_openai import ChatOpenAI
        
        # è·å–OpenAIé…ç½®
        openai_api_key = config.get_config().get("api.openai.api_key")
        if not openai_api_key:
            print("âŒ æœªæ‰¾åˆ°OpenAI APIå¯†é’¥ï¼Œè·³è¿‡æµ‹è¯•")
            return
        
        # åˆ›å»ºOpenAIæ¨¡å‹
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            api_key=openai_api_key,
            temperature=0
        )
        
        # ç»‘å®šå·¥å…·
        llm_with_tools = llm.bind_tools([test_tool])
        
        # åˆ›å»ºAgent
        agent = create_react_agent(
            model=llm_with_tools,
            tools=[test_tool]
        )
        
        print("âœ… OpenAI Agentåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æŸ¥è¯¢
        query = "è¯·ä½¿ç”¨TestToolå·¥å…·å¤„ç†ä¸€äº›æ•°æ®"
        print(f"æµ‹è¯•æŸ¥è¯¢: {query}")
        
        result = agent.invoke({
            "messages": [{"role": "user", "content": query}]
        })
        
        print(f"Agentç»“æœ: {result}")
        
        # æ£€æŸ¥æ¶ˆæ¯
        messages = result.get('messages', [])
        for i, msg in enumerate(messages):
            print(f"æ¶ˆæ¯ {i}: {type(msg).__name__} - {msg.content[:200]}...")
            
    except ImportError:
        print("âŒ æœªå®‰è£…langchain_openaiï¼Œå°è¯•ä½¿ç”¨å…¶ä»–æ¨¡å‹")
        try:
            from langchain_anthropic import ChatAnthropic
            
            # è·å–Anthropicé…ç½®
            anthropic_api_key = config.get_config().get("api.anthropic.api_key")
            if not anthropic_api_key:
                print("âŒ æœªæ‰¾åˆ°Anthropic APIå¯†é’¥ï¼Œè·³è¿‡æµ‹è¯•")
                return
            
            # åˆ›å»ºAnthropicæ¨¡å‹
            llm = ChatAnthropic(
                model="claude-3-haiku-20240307",
                api_key=anthropic_api_key,
                temperature=0
            )
            
            # ç»‘å®šå·¥å…·
            llm_with_tools = llm.bind_tools([test_tool])
            
            # åˆ›å»ºAgent
            agent = create_react_agent(
                model=llm_with_tools,
                tools=[test_tool]
            )
            
            print("âœ… Anthropic Agentåˆ›å»ºæˆåŠŸ")
            
            # æµ‹è¯•æŸ¥è¯¢
            query = "è¯·ä½¿ç”¨TestToolå·¥å…·å¤„ç†ä¸€äº›æ•°æ®"
            print(f"æµ‹è¯•æŸ¥è¯¢: {query}")
            
            result = agent.invoke({
                "messages": [{"role": "user", "content": query}]
            })
            
            print(f"Agentç»“æœ: {result}")
            
            # æ£€æŸ¥æ¶ˆæ¯
            messages = result.get('messages', [])
            for i, msg in enumerate(messages):
                print(f"æ¶ˆæ¯ {i}: {type(msg).__name__} - {msg.content[:200]}...")
                
        except ImportError:
            print("âŒ æœªå®‰è£…ç›¸å…³ä¾èµ–åŒ…")
            print("è¯·å®‰è£…: pip install langchain-openai langchain-anthropic")
            
    except Exception as e:
        print(f"âŒ Agentæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_direct_tool_calling()
    test_with_agent() 