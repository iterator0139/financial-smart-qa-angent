#!/usr/bin/env python3
"""
æµ‹è¯•å·¥å…·æ‰§è¡Œ
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parent
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

from langchain_core.tools import Tool
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.prebuilt import create_react_agent
from src.models.streaming_adapter import StreamingLLMAdapter
from src.config.config_manager import ConfigManager


def create_test_tool():
    """åˆ›å»ºä¸€ä¸ªæµ‹è¯•å·¥å…·"""
    
    def test_function(input_text: str) -> str:
        print(f"ğŸ¯ [REAL_TOOL_EXECUTION] å·¥å…·çœŸæ­£è¢«æ‰§è¡Œäº†ï¼")
        print(f"ğŸ“ [TOOL_INPUT] è¾“å…¥: {input_text}")
        result = f"å·¥å…·æ‰§è¡Œç»“æœ: {input_text}"
        print(f"ğŸ“¤ [TOOL_OUTPUT] è¾“å‡º: {result}")
        return result
    
    return Tool(
        name="TestTool",
        description="A test tool that prints execution logs",
        func=test_function
    )


def test_direct_tool():
    """ç›´æ¥æµ‹è¯•å·¥å…·"""
    print("=== ç›´æ¥æµ‹è¯•å·¥å…· ===")
    tool = create_test_tool()
    result = tool.func("æµ‹è¯•è¾“å…¥")
    print(f"ç›´æ¥è°ƒç”¨ç»“æœ: {result}")


def test_langgraph_agent():
    """æµ‹è¯•LangGraph Agent"""
    print("\n=== æµ‹è¯•LangGraph Agent ===")
    
    # åˆå§‹åŒ–é…ç½®
    config = ConfigManager()
    config_dir = Path(__file__).resolve().parent / "src" / "conf"
    config.init(config_dir)
    
    # åˆ›å»ºæµ‹è¯•å·¥å…·
    tool = create_test_tool()
    
    # åˆ›å»ºLLM
    llm = StreamingLLMAdapter(
        model="qwen-turbo",
        api_key=config.get_config().get("api.qwen.api_key"),
        base_url=config.get_config().get("api.qwen.base_url"),
        default_params={}
    )
    
    # åˆ›å»ºAgent
    agent = create_react_agent(
        model=llm,
        tools=[tool],
        prompt="Answer the following questions as best you can. You have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: {input}\nThought: I should use a tool to help answer this question.\nAction: {tool_names}\nObservation: {tool_outputs}\nThought: I now know the final answer.\nFinal Answer: {output}\n\nBegin!\n\nQuestion: {input}\nThought:{agent_scratchpad}"
    )
    
    print("âœ… Agentåˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "è¯·ä½¿ç”¨TestToolå·¥å…·å¤„ç†ä¸€äº›æ•°æ®"
    print(f"æµ‹è¯•æŸ¥è¯¢: {query}")
    
    try:
        result = agent.invoke({
            "messages": [{"role": "user", "content": query}]
        })
        
        print(f"Agentç»“æœ: {result}")
        
        # æ£€æŸ¥æ¶ˆæ¯
        messages = result.get('messages', [])
        for i, msg in enumerate(messages):
            print(f"æ¶ˆæ¯ {i}: {type(msg).__name__} - {msg.content[:100]}...")
            
    except Exception as e:
        print(f"âŒ Agentæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_with_custom_prompt():
    """ä½¿ç”¨è‡ªå®šä¹‰promptæµ‹è¯•"""
    print("\n=== ä½¿ç”¨è‡ªå®šä¹‰promptæµ‹è¯• ===")
    
    # åˆå§‹åŒ–é…ç½®
    config = ConfigManager()
    config_dir = Path(__file__).resolve().parent / "src" / "conf"
    config.init(config_dir)
    
    # åˆ›å»ºæµ‹è¯•å·¥å…·
    tool = create_test_tool()
    
    # åˆ›å»ºLLM
    llm = StreamingLLMAdapter(
        model="qwen-turbo",
        api_key=config.get_config().get("api.qwen.api_key"),
        base_url=config.get_config().get("api.qwen.base_url"),
        default_params={}
    )
    
    # è‡ªå®šä¹‰promptï¼Œå¼ºåˆ¶ä½¿ç”¨å·¥å…·
    custom_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚

å¯ç”¨å·¥å…·ï¼š
{tools}

ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
Question: ç”¨æˆ·é—®é¢˜
Thought: æˆ‘éœ€è¦æ€è€ƒå¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜
Action: å·¥å…·åç§°
Action Input: å·¥å…·è¾“å…¥
Observation: å·¥å…·è¾“å‡º
... (å¯ä»¥é‡å¤å¤šæ¬¡)
Thought: æˆ‘ç°åœ¨çŸ¥é“ç­”æ¡ˆäº†
Final Answer: æœ€ç»ˆç­”æ¡ˆ

å¼€å§‹ï¼

Question: {input}
{agent_scratchpad}"""
    
    # åˆ›å»ºAgent
    agent = create_react_agent(
        model=llm,
        tools=[tool],
        prompt=custom_prompt
    )
    
    print("âœ… è‡ªå®šä¹‰Agentåˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "è¯·ä½¿ç”¨TestToolå·¥å…·å¤„ç†ä¸€äº›æ•°æ®"
    print(f"æµ‹è¯•æŸ¥è¯¢: {query}")
    
    try:
        result = agent.invoke({
            "messages": [{"role": "user", "content": query}]
        })
        
        print(f"Agentç»“æœ: {result}")
        
        # æ£€æŸ¥æ¶ˆæ¯
        messages = result.get('messages', [])
        for i, msg in enumerate(messages):
            print(f"æ¶ˆæ¯ {i}: {type(msg).__name__} - {msg.content[:200]}...")
            
    except Exception as e:
        print(f"âŒ Agentæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_direct_tool()
    test_langgraph_agent()
    test_with_custom_prompt() 